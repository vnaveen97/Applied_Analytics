---
title: "Homework 5: Classification"
subtitle: 'STAT656'
output: html_document
---

# Digits data

In this assignment, we are going to revisit the digits data example from class.  For a more information about this, see the posted lectures videos (Parts 1 through 5) and marsAndFDA2.Rmd.

Following the discussion in class, let's look at hand draw 5s and 8s

# Packages and helper function

```{r packages}
require(dplyr)
require(earth)     # fit MARS models
require(caret)     # automating the tuning process
require(vip)       # variable importance
require(glmnet)
require(lattice)   # to plot digits
require(pROC)
require(neuralnet)
require(doParallel)
```

Also, here is a helper function for plotting the vectorized digit back into an image:

```{r plotDigit}
plotDigit = function(x) {
  cols = gray.colors(100, start = 0, end = 1, rev=TRUE)
  matObj = matrix(x,nrow=28)[,28:1]
  mode(matObj) = 'numeric'
  levelplot(matObj,col.regions=cols, xlab = '', ylab = '')
}
```


Let's read in the data set. 

```{r readData, cache = TRUE}
training = read.csv('digits.csv')
Y = make.names(training$label)
X = select(training, -label) %>% filter( Y == 'X5'| Y == 'X8')
Y = as.factor(Y[Y == 'X5' | Y == 'X8'])

set.seed(1)
trainSplit = createDataPartition(y = Y, p = 0.8, list = FALSE)

Ytrain = Y[trainSplit]
Xtrain = X[trainSplit,]
XtrainMat = as.matrix(Xtrain)
Ytest  = Y[-trainSplit]
Xtest  = X[-trainSplit,]
XtestMat = as.matrix(Xtest)
```


Here are some example plots:

```{r examplePlots}
plotObj = vector('list',9)
for(j in 1:9){
	plotObj[[j]] = plotDigit(X[j,])	
}
do.call(grid.arrange, plotObj)
```


# Problem 1 (30 pts). Logistic elastic net.

Let's look at a fitting the logistic elastic net

```{r logisticElasticNet, cache = TRUE}
set.seed(1)
K            = 5
trainControl = trainControl(method = "cv", number = K)
tuneGrid     = expand.grid('alpha'=c(.5, 1),'lambda' = seq(0.0001, .01, length.out = 10))

elasticOut   = train(x = XtrainMat, y = Ytrain, method = "glmnet", trControl = trainControl, tuneGrid = tuneGrid)

elasticOut$bestTune
```

Using these selected tuning parameters, let's get some predictions on the test digits data

```{r}
glmnetOut         = glmnet(x = XtrainMat, y = relevel(Ytrain, ref = 'X8'), 
                           alpha = elasticOut$bestTune$alpha, family = 'binomial')
probHatTestGlmnet = predict(glmnetOut, XtestMat, s=elasticOut$bestTune$lambda, type = 'response')
YhatTestGlmnet    = ifelse(probHatTestGlmnet > 0.5, 'X5', 'X8')
```


We can look at the active set as well.  For this assignment, just to make the picture easier to explain, we will use a threshold of 0.005 instead of something near 0.

```{r}
betaHat = coef(glmnetOut, s=elasticOut$bestTune$lambda)
Sglmnet = abs(betaHat[-1]) > .005
```

By looking at the estimated coefficients, we can gain insight into which pixels seem to be associated with 
each digit.  Also, as the features are standardized, we can use the coefficient magnitude to rank the features in importance

```{r importantGlmnet}
importantGlmnet = betaHat[-1][Sglmnet] 

importantDigit = rep(0,28**2)
importantDigit[Sglmnet] = importantGlmnet/max(abs(importantGlmnet))

plotDigit(importantDigit)
```

Let's compare these important pixels to a few digits from the training data

```{r}
plotObj = vector('list',9)
plotObj[[1]] = plotDigit(importantDigit)
for(j in 2:9){
	plotObj[[j]] = plotDigit(X[j,])	
}
do.call(grid.arrange, plotObj )
```

#### Answer 1.3

Describe this image by identifying pixels that seem to be positively associated with Y = 'X5' and positively associated with Y = 'X8'.

```{r}
posx5 = which.max(importantDigit)
posx8 = which.min(importantDigit)
```

Considering Y = 'x5' as the event, pixels that appear black in color(Beta > 0) from the above graph, is positively associated with Y = 'x5' and that appear white in color(Beta < 0) is positively associated with Y = 'x8'.Pixel `r posx5` is the highest positively associated feature with Y = 'x5' and pixel `r posx8` is the highest positively associated feature with Y = 'x8'.

# Problem 2 (40 points). MARS applied to classification

### Problem 2.1

Let's look at applying MARS to digits using the *caret* package

```{r mars, cache = TRUE}
clust <- makePSOCKcluster(5)
registerDoParallel(clust)

fdaOut = train(x = Xtrain, 
                y = Ytrain,
                method = 'fda',
                metric = 'Accuracy',
                tuneGrid = expand.grid(degree = 1:3, nprune = c(10,20,50,100)),
                trControl = trainControl(method='CV',number = K, classProbs = TRUE))
fdaOut
plot(fdaOut)

stopCluster(clust)
```

#### Answer 2.1

What values of degree and nprune are selected by maximizing CV accuracy?

```{r best}
deg    = fdaOut$bestTune[[1]]
nprune = fdaOut$bestTune[[2]]
```

A degree of `r deg` and nprune of `r nprune` are selected for maximizing the cv accuracy.

### Problem 2.2

We can also get the feature importance out
```{r}
fdaVip = vip(fdaOut,num_features = 40, bar = FALSE, metric = "Accuracy")
plot(fdaVip)
```

#### Answer 2.2

Which pixel is the most important for discriminating between 5 and 8?  How could you go about getting a general idea if that pixel is associated with the class '5' or '8'?  Which do you conclude?

```{r coefficients}
print(coef(fdaOut$finalModel))

coeffs = coef(fdaOut$finalModel)[-1]

class5 = coeffs[which.max(coeffs)]

class8 = coeffs[which.min(coeffs)]
```

By looking at the coefficients of FDA model, h(40-pixel326) with a coefficient of `r class5` and h(2-pixel183)*h(pixel296-248) with a coefficient of `r class8` are the most important in discriminating between class 5 and class 8. Generally, positive coefficients are associated with class 5 and negative coefficients are associated with class 8.

### Problem 2.3

Let's look at the importance object we computed with *vip*

```{r}
important    = fdaVip$data$Variable[fdaVip$data$Importance > 1e-16]
importantVal = fdaVip$data$Importance[fdaVip$data$Importance > 1e-16]
#here we are getting the pixel number + 1 to get the feature index
importantIndex = sapply(strsplit(important,'pixel'),function(x){return(as.numeric(x[2])+1)})

importantDigit1 = rep(0,28**2)
importantDigit1[importantIndex] = importantVal/max(importantVal)

plotDigit(importantDigit1)
```

Again, comparing the importance plot to some digits from the training data

```{r}
plotObj = vector('list',9)
plotObj[[1]] = plotDigit(importantDigit1)
for(j in 2:9){
	plotObj[[j]] = plotDigit(X[j,])	
}
do.call(grid.arrange, plotObj )
```

#### Answer 2.3.

Why do you think these pixels would be important for discriminating between Y = 'X5' and Y = 'X8'.

Using this plot it is difficult to differentiate the pixels between classes 5 and 8 as these just show only the pixels that are important not the coefficients. From the plot, the two joint reversed c-shaped curve(right half of 8) helps in identifying the class 8, but it does not consider the left half. For class 5, if we look at the plot with intensity 1.0(three black pixels horizontally arranged), these help to differentiate between class 8 as 5 has a more lengthy bottom horizontal line than 8.  

# Predictions on the test set

Remember that when you see the word 'posterior' when looking at a classification method, you should think 'probability estimate'

```{r }
probHatTestFDA = predict(fdaOut$finalModel, Xtest, type='posterior')
YhatTestFDA    =  ifelse(probHatTestFDA[,1] > 0.5, 'X5', 'X8')
```

The confusion matrices
```{r}
table(YhatTestGlmnet, Ytest)

table(YhatTestFDA, Ytest)
```

#### Answer 2.4. 

Which method has the highest sensitivity and what is that sensitivity?

FDA has the highest sensitivity(TP/(TP + FN)) with a value of 0.9723

#### Answer 2.5. 

Which method has the highest specificity and what is that specificity?

Glmnet has the highest specificity(TN/(TN + FP)) with a value of 0.969

#### Answer 2.6. 

Which method has the highest precision and what is that precision?

Glmnet has the highest precision(TP/(TP + FP)) with a value of 0.967

# ROC curves

Let's directly compare the ROC curves.  The *roc* function expects the probability estimates to be vectors and right now the glmnet probability estimates are in a $n_test$ by 1 matrix. We can fix that:
```{r}
probHatTestGlmnet = as.numeric(probHatTestGlmnet)
```

```{r roc}
rocOutGlmnet = roc(response = Ytest, probHatTestGlmnet)
plot(rocOutGlmnet)
rocOutFDA = roc(response = Ytest, probHatTestFDA[,1])
plot(rocOutFDA, col = 'red', add = TRUE)
```

#### Answer 2.7. 

Which method has the highest AUC?
```{r}
glmnetAUC = rocOutGlmnet$auc
fdaAUC    = rocOutFDA$auc
```

FDA has the the highest AUC with a value of `r fdaAUC`.

# Problem 3. (30 pts) Neural networks

### Problem 3.1
Let's fit a simple neural network to these data as well

```{r neuralNet, cache = TRUE}

clust <- makePSOCKcluster(5)
registerDoParallel(clust)

set.seed(1)
nnOut = neuralnet(Ytrain~.,data=Xtrain, 
                  hidden=2, rep = 3, 
                  err.fct = 'ce', linear.output = FALSE)

Wrep1 = nnOut$weights[[1]][[1]]
Wrep2 = nnOut$weights[[2]][[1]]
Wrep3 = nnOut$weights[[3]][[1]]
W = (Wrep1 + Wrep2 + Wrep3)/3

plot(W[-1,],type='n',xlab='W_1',ylab='W_2')
text(W[-1,],names(X),cex=.25)

stopCluster(clust)
```

#### Answer 3.1

Which pixels appear to be most different based on the first hidden unit (W_1)?  Which pixels appear to be most different based on the second hidden unit (W_2)? As a reminder, these Ws are the same as the 'gammas' from the lecture notes.

Features (pixels) at the extreme end of the plot are the most different. For W_1, by eyeballing pixel 424 and 118 appears to be most different. Similarly, for W_2, pixel 424 and 93 appears to be most different.

### Problem 3.2   

We will get predictions with the neural network model.  We will average the probability estimates from each of the three model fits (from 3 different random starting values.  Remember: the solution you get with neural networks depends on where you started)

```{r}
pHatNN1 = predict(nnOut, Xtest, rep = 1)
pHatNN2 = predict(nnOut, Xtest, rep = 2)
pHatNN3 = predict(nnOut, Xtest, rep = 3)

pHatNN  = (pHatNN1 + pHatNN2 + pHatNN3)/3

YhatTestNN    = ifelse(pHatNN[,1] > 0.5, 'X5', 'X8')

table(YhatTestNN, Ytest)
```

#### Answer 3.2

These results are much worse than for FDA or logistic elastic net.  What strategies could you employ to improve the neural network results?

To get better predictions using the neural networks, one method would be to iterate, increase or decrease over the number of hidden neurons or to increase the number of repetitions for the neural network's training.

# Extra credit (10 pts)

Attempt one of the strategies you suggested in the previous answer.  Report the new test confusion matrix. Did it improve the test accuracy?
```{r}
clust <- makePSOCKcluster(5)
registerDoParallel(clust)

set.seed(1)
nnOut2 = neuralnet(Ytrain~.,data=Xtrain, 
                  hidden=5, rep = 3, 
                  err.fct = 'ce', linear.output = FALSE)

pHatNN1 = predict(nnOut2, Xtest, rep = 1)
pHatNN2 = predict(nnOut2, Xtest, rep = 2)
pHatNN3 = predict(nnOut2, Xtest, rep = 3)

pHatNN2  = (pHatNN1 + pHatNN2 + pHatNN3)/3

YhatTestNN2    = ifelse(pHatNN2[,1] > 0.5, 'X5', 'X8')

table(YhatTestNN2, Ytest)

stopCluster(clust)
```

Accuracy and Sensitivity for the second neural network model has been increased when compared to the first neural network model, but the specificity has  decreased.
